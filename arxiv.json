[
    {
        "title": "FinVet: A Collaborative Framework of RAG and External Fact-Checking\n  Agents for Financial Misinformation Detection",
        "url": "http://arxiv.org/abs/2510.11654v1",
        "pub_date": "2025-10-13",
        "summary": "Financial markets face growing threats from misinformation that can trigger billions in losses in minutes. Most existing approaches lack transparency in their decision-making and provide limited attribution to credible sources. We introduce FinVet, a novel multi-agent framework that integrates two Retrieval-Augmented Generation (RAG) pipelines with external fact-checking through a confidence-weighted voting mechanism. FinVet employs adaptive three-tier processing that dynamically adjusts verification strategies based on retrieval confidence, from direct metadata extraction to hybrid reasoning to full model-based analysis. Unlike existing methods, FinVet provides evidence-backed verdicts, source attribution, confidence scores, and explicit uncertainty flags when evidence is insufficient. Experimental evaluation on the FinFact dataset shows that FinVet achieves an F1 score of 0.85, which is a 10.4% improvement over the best individual pipeline (fact-check pipeline) and 37% improvement over standalone RAG approaches.",
        "translated": "金融市场正面临日益严重的虚假信息威胁，这些信息可能在几分钟内引发数十亿美元的损失。大多数现有方法在决策过程中缺乏透明度，并且对可信来源的归因有限。我们提出 FinVet，一个新颖的多智能体框架，通过置信度加权投票机制，将两个检索增强生成（Retrieval-Augmented Generation, RAG）流水线与外部事实核查相结合。FinVet 采用自适应的三级处理流程，根据检索置信度动态调整验证策略，从直接元数据提取，到混合推理，再到基于模型的完整分析。与现有方法不同，FinVet 在证据不足时提供基于证据的判定结果、来源归因、置信度评分以及明确的不确定性标记。在 FinFact 数据集上的实验评估表明，FinVet 达到 0.85 的 F1 分数，相比最优的单一流水线（事实核查流水线）提高了 10.4%，相比独立的 RAG 方法提高了 37%。"
    },
    {
        "title": "OneRec-Think: In-Text Reasoning for Generative Recommendation",
        "url": "http://arxiv.org/abs/2510.11639v1",
        "pub_date": "2025-10-13",
        "summary": "The powerful generative capacity of Large Language Models (LLMs) has instigated a paradigm shift in recommendation. However, existing generative models (e.g., OneRec) operate as implicit predictors, critically lacking the capacity for explicit and controllable reasoning-a key advantage of LLMs. To bridge this gap, we propose OneRec-Think, a unified framework that seamlessly integrates dialogue, reasoning, and personalized recommendation. OneRec-Think incorporates: (1) Itemic Alignment: cross-modal Item-Textual Alignment for semantic grounding; (2) Reasoning Activation: Reasoning Scaffolding to activate LLM reasoning within the recommendation context; and (3) Reasoning Enhancement, where we design a recommendation-specific reward function that accounts for the multi-validity nature of user preferences. Experiments across public benchmarks show state-of-the-art performance. Moreover, our proposed \"Think-Ahead\" architecture enables effective industrial deployment on Kuaishou, achieving a 0.159\\% gain in APP Stay Time and validating the practical efficacy of the model's explicit reasoning capability.",
        "translated": "大型语言模型（LLMs）强大的生成能力正在引发推荐系统领域的一场范式转变。然而，现有的生成模型（例如 OneRec）主要作为隐式预测器运行，严重缺乏显式可控推理的能力——而这正是 LLMs 的关键优势所在。为了解决这一问题，我们提出了 OneRec-Think，一个统一的框架，能够无缝融合对话、推理与个性化推荐。OneRec-Think 包含以下三个核心模块：（1）Itemic 对齐：跨模态的物品-文本对齐，以实现语义基础的构建；（2）推理激活：通过推理结构（Reasoning Scaffolding）在推荐场景中激活 LLM 的推理能力；以及（3）推理增强：我们设计了一个面向推荐任务的奖励函数，以应对用户偏好的多合理性（multi-validity）特性。在多个公开基准上的实验表明，该方法取得了最先进的性能。此外，我们提出的“Think-Ahead”架构在快手平台实现了有效的工业部署，使得 APP 使用时长提升了 0.159%，验证了模型显式推理能力的实用效果。"
    },
    {
        "title": "SemCSE-Multi: Multifaceted and Decodable Embeddings for Aspect-Specific\n  and Interpretable Scientific Domain Mapping",
        "url": "http://arxiv.org/abs/2510.11599v1",
        "pub_date": "2025-10-13",
        "summary": "We propose SemCSE-Multi, a novel unsupervised framework for generating multifaceted embeddings of scientific abstracts, evaluated in the domains of invasion biology and medicine. These embeddings capture distinct, individually specifiable aspects in isolation, thus enabling fine-grained and controllable similarity assessments as well as adaptive, user-driven visualizations of scientific domains. Our approach relies on an unsupervised procedure that produces aspect-specific summarizing sentences and trains embedding models to map semantically related summaries to nearby positions in the embedding space. We then distill these aspect-specific embedding capabilities into a unified embedding model that directly predicts multiple aspect embeddings from a scientific abstract in a single, efficient forward pass. In addition, we introduce an embedding decoding pipeline that decodes embeddings back into natural language descriptions of their associated aspects. Notably, we show that this decoding remains effective even for unoccupied regions in low-dimensional visualizations, thus offering vastly improved interpretability in user-centric settings.",
        "translated": "我们提出了一种名为 SemCSE-Multi 的新型无监督框架，用于生成科学摘要的多方面嵌入表示，并在入侵生物学和医学领域进行了评估。该嵌入能够独立捕捉多个明确且可单独指定的方面，从而支持细粒度、可控的相似性评估，以及自适应的、以用户驱动的科学领域可视化。我们的方法依赖于一个无监督过程，首先生成特定方面的总结性句子，并训练嵌入模型将语义相关的摘要映射到嵌入空间中的相近位置。随后，我们将这些特定方面的嵌入能力提炼到一个统一的嵌入模型中，使其能够在一个高效、单一的前向传播过程中直接从科学摘要中预测出多个方面嵌入。此外，我们还引入了一个嵌入解码流程，将嵌入表示还原为与各特定方面相关的自然语言描述。值得注意的是，我们证明了即使在低维可视化中未被占用的区域，该解码过程依然有效，从而在以用户为中心的应用场景中显著提升了可解释性。"
    },
    {
        "title": "REGENT: Relevance-Guided Attention for Entity-Aware Multi-Vector Neural\n  Re-Ranking",
        "url": "http://arxiv.org/abs/2510.11592v1",
        "pub_date": "2025-10-13",
        "summary": "Current neural re-rankers often struggle with complex information needs and long, content-rich documents. The fundamental issue is not computational--it is intelligent content selection: identifying what matters in lengthy, multi-faceted texts. While humans naturally anchor their understanding around key entities and concepts, neural models process text within rigid token windows, treating all interactions as equally important and missing critical semantic signals. We introduce REGENT, a neural re-ranking model that mimics human-like understanding by using entities as a \"semantic skeleton\" to guide attention. REGENT integrates relevance guidance directly into the attention mechanism, combining fine-grained lexical matching with high-level semantic reasoning. This relevance-guided attention enables the model to focus on conceptually important content while maintaining sensitivity to precise term matches. REGENT achieves new state-of-the-art performance in three challenging datasets, providing up to 108% improvement over BM25 and consistently outperforming strong baselines including ColBERT and RankVicuna. To our knowledge, this is the first work to successfully integrate entity semantics directly into neural attention, establishing a new paradigm for entity-aware information retrieval.",
        "translated": "目前的神经重排序模型在处理复杂的信息需求和长篇、内容丰富文档时常常面临挑战。其根本问题并不在于计算能力，而在于智能内容选择：识别长篇、多维文本中真正重要的信息。尽管人类在理解文本时自然地围绕关键实体和概念进行定位，但神经模型则受限于固定的词元窗口对文本进行处理，将所有交互视为同等重要，从而忽略了关键的语义信号。我们提出REGENT，这是一种神经重排序模型，通过使用实体作为“语义骨架”来引导注意力，从而模拟人类的理解方式。REGENT将相关性引导直接整合到注意力机制中，将细粒度的词汇匹配与高层次的语义推理相结合。这种相关性引导的注意力机制使模型能够聚焦于概念上重要的内容，同时保持对精确术语匹配的敏感性。REGENT在三个具有挑战性的数据集上达到了新的最先进性能，在BM25基础上最多提升了108%，并且始终优于ColBERT和RankVicuna等强基线模型。据我们所知，这是首次成功将实体语义直接整合到神经注意力机制中的工作，为具备实体感知能力的信息检索建立了一个新的范式。"
    },
    {
        "title": "QDER: Query-Specific Document and Entity Representations for\n  Multi-Vector Document Re-Ranking",
        "url": "http://arxiv.org/abs/2510.11589v1",
        "pub_date": "2025-10-13",
        "summary": "Neural IR has advanced through two distinct paths: entity-oriented approaches leveraging knowledge graphs and multi-vector models capturing fine-grained semantics. We introduce QDER, a neural re-ranking model that unifies these approaches by integrating knowledge graph semantics into a multi-vector model. QDER's key innovation lies in its modeling of query-document relationships: rather than computing similarity scores on aggregated embeddings, we maintain individual token and entity representations throughout the ranking process, performing aggregation only at the final scoring stage - an approach we call \"late aggregation.\" We first transform these fine-grained representations through learned attention patterns, then apply carefully chosen mathematical operations for precise matches. Experiments across five standard benchmarks show that QDER achieves significant performance gains, with improvements of 36% in nDCG@20 over the strongest baseline on TREC Robust 2004 and similar improvements on other datasets. QDER particularly excels on difficult queries, achieving an nDCG@20 of 0.70 where traditional approaches fail completely (nDCG@20 = 0.0), setting a foundation for future work in entity-aware retrieval.",
        "translated": "神经信息检索（Neural IR）的发展经历了两条不同的路径：一种是面向实体的方法，利用知识图谱信息；另一种是多向量模型，用于捕捉细粒度语义。我们提出 QDER，这是一种神经重排序模型，通过将知识图谱语义整合到多向量模型中，实现了这两条路径的统一。QDER 的关键创新在于其对查询与文档关系的建模：与在聚合嵌入上计算相似度分数的传统方法不同，我们在整个排序过程中保留每个词元（token）和实体的独立表示，仅在最终的评分阶段进行聚合——我们称这种策略为“晚期聚合”（late aggregation）。首先，我们通过学习得到的注意力模式对这些细粒度表示进行转换，然后应用精心选择的数学运算以实现精确匹配。在五个标准基准数据集上的实验表明，QDER 显著提升了性能，在 TREC Robust 2004 数据集上相比最强基线模型的 nDCG@20 提高了 36%，在其他数据集上也有类似提升。尤其在处理困难查询时，QDER 表现出色，取得了 0.70 的 nDCG@20 评分，而传统方法在此类查询上完全失效（nDCG@20 = 0.0），为未来实体感知（entity-aware）检索的研究奠定了基础。"
    },
    {
        "title": "Characterizing Web Search in The Age of Generative AI",
        "url": "http://arxiv.org/abs/2510.11560v1",
        "pub_date": "2025-10-13",
        "summary": "The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response. This output modality stands in stark contrast to traditional web search, where results are returned as a ranked list of independent web pages. In this paper, we ask: Along what dimensions do generative search outputs differ from traditional web search? We compare Google, a traditional web search engine, with four generative search engines from two providers (Google and OpenAI) across queries from four domains. Our analysis reveals intriguing differences. Most generative search engines cover a wider range of sources compared to web search. Generative search engines vary in the degree to which they rely on internal knowledge contained within the model parameters v.s. external knowledge retrieved from the web. Generative search engines surface varying sets of concepts, creating new opportunities for enhancing search diversity and serendipity. Our results also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.",
        "translated": "大语言模型（LLMs）的出现催生了一种新的网络搜索方式：生成式搜索（generative search），在这种搜索方式中，LLMs会检索与查询相关的网页，并生成一段连贯统一的文本作为响应。这种输出形式与传统网络搜索形成了鲜明对比，后者返回的是一个按相关性排序的独立网页列表。在本文中，我们提出以下问题：生成式搜索的输出在哪些维度上与传统网络搜索有所不同？我们从四个领域中选取查询，比较了传统网络搜索引擎Google与来自两家提供商（Google和OpenAI）的四个生成式搜索引擎的表现。我们的分析揭示了一些有趣的差异。大多数生成式搜索引擎相比传统网络搜索，能够涵盖更广泛的来源。生成式搜索引擎在依赖模型参数中包含的内部知识与从网络检索的外部知识的程度上存在差异。此外，生成式搜索引擎展示的概念集合各不相同，从而为提升搜索多样性和偶然性提供了新的可能性。我们的结果还强调，在生成式人工智能时代，有必要重新审视网络搜索的评估标准。"
    },
    {
        "title": "Uncertainty Quantification for Retrieval-Augmented Reasoning",
        "url": "http://arxiv.org/abs/2510.11483v1",
        "pub_date": "2025-10-13",
        "summary": "Retrieval-augmented reasoning (RAR) is a recent evolution of retrieval-augmented generation (RAG) that employs multiple reasoning steps for retrieval and generation. While effective for some complex queries, RAR remains vulnerable to errors and misleading outputs. Uncertainty quantification (UQ) offers methods to estimate the confidence of systems' outputs. These methods, however, often handle simple queries with no retrieval or single-step retrieval, without properly handling RAR setup. Accurate estimation of UQ for RAR requires accounting for all sources of uncertainty, including those arising from retrieval and generation. In this paper, we account for all these sources and introduce Retrieval-Augmented Reasoning Consistency (R2C)--a novel UQ method for RAR. The core idea of R2C is to perturb the multi-step reasoning process by applying various actions to reasoning steps. These perturbations alter the retriever's input, which shifts its output and consequently modifies the generator's input at the next step. Through this iterative feedback loop, the retriever and generator continuously reshape one another's inputs, enabling us to capture uncertainty arising from both components. Experiments on five popular RAR systems across diverse QA datasets show that R2C improves AUROC by over 5% on average compared to the state-of-the-art UQ baselines. Extrinsic evaluations using R2C as an external signal further confirm its effectiveness for two downstream tasks: in Abstention, it achieves ~5% gains in both F1Abstain and AccAbstain; in Model Selection, it improves the exact match by ~7% over single models and ~3% over selection methods.",
        "translated": "检索增强推理（Retrieval-Augmented Reasoning, RAR）是检索增强生成（Retrieval-Augmented Generation, RAG）的最新演进，其通过在检索与生成过程中引入多步推理来提高效果。尽管在处理某些复杂查询时表现出色，RAR 仍然容易受到错误和误导性输出的影响。不确定性量化（Uncertainty Quantification, UQ）提供了一种估计系统输出置信度的方法。然而，现有方法大多针对无检索或单步检索的简单查询，未能有效应对 RAR 的设置。对 RAR 的 UQ 进行准确估计，需要综合考虑所有可能的不确定性来源，包括检索和生成过程中的不确定性。在本文中，我们系统地考虑了这些不确定性来源，并提出了检索增强推理一致性（Retrieval-Augmented Reasoning Consistency, R2C）——一种新型的 UQ 方法。R2C 的核心思想是通过对推理步骤施加多种操作，扰动多步推理过程。这些扰动会改变检索器的输入，从而影响其输出，并进一步修改生成器在下一步的输入。通过这一迭代反馈机制，检索器和生成器不断重塑彼此的输入，使我们能够捕捉来自两个组件的不确定性。在五个主流 RAR 系统和多个问答数据集上的实验表明，与最先进的 UQ 基线方法相比，R2C 在平均 AUROC 指标上提升了超过 5%。使用 R2C 作为外部信号进行的外在评估进一步验证了其有效性，针对两个下游任务：在拒绝回答（Abstention）任务中，R2C 在 F1Abstain 和 AccAbstain 指标上分别提升了约 5%；在模型选择（Model Selection）任务中，R2C 相比单模型提升了约 7% 的精确匹配（exact match），相比其他选择方法提升了约 3%。"
    },
    {
        "title": "What Generative Search Engines Like and How to Optimize Web Content\n  Cooperatively",
        "url": "http://arxiv.org/abs/2510.11438v1",
        "pub_date": "2025-10-13",
        "summary": "By employing large language models (LLMs) to retrieve documents and generate natural language responses, Generative Engines, such as Google AI overview and ChatGPT, provide significantly enhanced user experiences and have rapidly become the new form of search. Their rapid adoption also drives the needs of Generative Engine Optimization (GEO), as content providers are eager to gain more traction from them. In this paper, we introduce AutoGEO, a framework to automatically learn generative engine preferences when using retrieved contents for response generation, and rewrite web contents for more such traction. AutoGEO first prompts frontier LLMs to explain generative engine preferences and extract meaningful preference rules from these explanations. Then it uses preference rules as context engineering for AutoGEO$_\\text{API}$, a prompt-based GEO system, and as rule-based rewards to train AutoGEO$_\\text{Mini}$, a cost-effective GEO model. Experiments on the standard GEO-Bench and two newly constructed benchmarks using real user queries demonstrate the effectiveness of AutoGEO in enhancing content traction while preserving search utility. Analyses confirm the learned rules' robustness and abilities to capture unique preferences in variant domains, and AutoGEO systems' ability to embed them in content optimization. The code is released at https://github.com/cxcscmu/AutoGEO.",
        "translated": "通过使用大语言模型（LLMs）来检索文档并生成自然语言响应，生成式引擎（如 Google AI 概述和 ChatGPT）显著提升了用户体验，并迅速成为搜索的新形态。其迅速普及也推动了生成式引擎优化（Generative Engine Optimization, GEO）的需求，因为内容提供者希望从这些系统中获得更多曝光。在本文中，我们提出了 AutoGEO，一个在使用检索内容进行响应生成时，能够自动学习生成式引擎偏好的框架，并对网页内容进行重写以提高其曝光度。AutoGEO 首先提示前沿的大语言模型解释生成式引擎的偏好，并从这些解释中提取有意义的偏好规则。接着，它将这些偏好规则用于 AutoGEO$_\\text{API}$——一个基于提示的 GEO 系统——作为上下文工程的输入，并将规则作为奖励机制，用于训练 AutoGEO$_\\text{Mini}$——一个经济高效的 GEO 模型。在标准的 GEO-Bench 基准以及基于真实用户查询构建的两个新基准上的实验表明，AutoGEO 在提升内容曝光度的同时能够保持搜索效用的有效性。分析结果进一步验证了所学习规则的鲁棒性及其在不同领域中捕捉独特偏好的能力，并确认了 AutoGEO 系统在内容优化中嵌入这些规则的能力。代码已发布在 https://github.com/cxcscmu/AutoGEO。"
    },
    {
        "title": "On Inherited Popularity Bias in Cold-Start Item Recommendation",
        "url": "http://arxiv.org/abs/2510.11402v1",
        "pub_date": "2025-10-13",
        "summary": "Collaborative filtering (CF) recommender systems struggle with making predictions on unseen, or 'cold', items. Systems designed to address this challenge are often trained with supervision from warm CF models in order to leverage collaborative and content information from the available interaction data. However, since they learn to replicate the behavior of CF methods, cold-start models may therefore also learn to imitate their predictive biases. In this paper, we show that cold-start systems can inherit popularity bias, a common cause of recommender system unfairness arising when CF models overfit to more popular items, thereby maximizing user-oriented accuracy but neglecting rarer items. We demonstrate that cold-start recommenders not only mirror the popularity biases of warm models, but are in fact affected more severely: because they cannot infer popularity from interaction data, they instead attempt to estimate it based solely on content features. This leads to significant over-prediction of certain cold items with similar content to popular warm items, even if their ground truth popularity is very low. Through experiments on three multimedia datasets, we analyze the impact of this behavior on three generative cold-start methods. We then describe a simple post-processing bias mitigation method that, by using embedding magnitude as a proxy for predicted popularity, can produce more balanced recommendations with limited harm to user-oriented cold-start accuracy.",
        "translated": "协同过滤（Collaborative Filtering, CF）推荐系统在对未见过的或“冷启动”的物品进行预测时面临挑战。为了解决这一问题，设计用于冷启动场景的系统通常会借助“热启动”CF模型进行监督训练，以利用现有的交互数据中的协作信息和内容信息。然而，由于这些系统学习的是复制CF方法的行为，因此冷启动模型也可能学会模仿其预测偏差。本文中，我们表明冷启动系统可能会继承“流行度偏差”（popularity bias），这是推荐系统不公平性的常见原因，当CF模型过度拟合更受欢迎的物品时就会产生这种偏差，从而在最大化面向用户准确率的同时忽略了较少出现的物品。我们通过实验发现，冷启动推荐器不仅复制了热模型的流行度偏差，而且实际上受到更严重的影响：由于它们无法从交互数据中推断出流行度，因此转而尝试仅基于内容特征来估计流行度。这导致某些与热门热启动物品在内容上相似的冷启动物品被显著高估，即使它们的真实流行度非常低。我们在三个多媒体数据集上分析了这一行为对三种生成式冷启动方法的影响。随后，我们介绍了一种简单的后处理偏差缓解方法，该方法通过将嵌入（embedding）模长作为预测流行度的代理指标，能够在有限地影响面向用户冷启动准确率的前提下，生成更加平衡的推荐结果。"
    },
    {
        "title": "VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation\n  via Rigorous Verification",
        "url": "http://arxiv.org/abs/2510.11394v1",
        "pub_date": "2025-10-13",
        "summary": "Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for enhancing the responses of large language models (LLMs) with external knowledge sources. Despite the impressive performance in complex question-answering tasks, RAG still struggles with hallucinations. Attributing RAG-generated content through in-line citations has demonstrated potential in reducing hallucinations and facilitating human verification. Existing citation generation methods primarily rely on either fine-tuning the generator or employing post-processing approaches for citation matching. However, the former approach demands substantial annotated data and computational resources, while the latter often encounters difficulties in managing multiple citations and frequently produces suboptimal results. In this paper, we introduce a novel framework, called VeriCite, designed to rigorously validate supporting evidence and enhance answer attribution. Specifically, VeriCite breaks down into a three-stage generation: 1) The initial answer generation first generates a response based on all available contexts and has its claims verified through the NLI model; 2) the supporting evidence selection assesses the utility of each document and extracts useful supporting evidences; 3) the final answer refinement integrates the initial response and collected evidences to produce the final, refined answer.We conduct experiments across five open-source LLMs and four datasets, demonstrating that VeriCite can significantly improve citation quality while maintaining the correctness of the answers.",
        "translated": "检索增强生成（Retrieval-Augmented Generation, RAG）已成为一种关键方法，用于通过外部知识源增强大语言模型（Large Language Models, LLMs）的响应能力。尽管RAG在复杂问答任务中表现出色，但其仍面临幻觉（hallucination）问题。通过行内引用（in-line citations）对RAG生成的内容进行归因，已被证明在减少幻觉和便于人工验证方面具有潜力。现有的引用生成方法主要依赖于对生成器的微调，或采用后处理方法进行引用匹配。然而，前者需要大量标注数据和计算资源，而后者在处理多个引用时常常遇到困难，且结果往往不够理想。在本文中，我们提出了一种新颖的框架，命名为VeriCite，旨在严格验证支持证据并提升答案归因能力。具体而言，VeriCite分为三个生成阶段：1）初始答案生成阶段基于所有可用上下文生成初步回答，并通过自然语言推理模型（NLI model）对其主张进行验证；2）支持证据选择阶段评估每个文档的有用性，并提取有效的支持证据；3）最终答案优化阶段整合初始回答与收集到的证据，生成最终的、经过优化的答案。我们在五种开源大语言模型和四个数据集上进行了实验，结果表明，VeriCite在保持答案正确性的同时，能够显著提升引用质量。"
    },
    {
        "title": "LLM-Specific Utility: A New Perspective for Retrieval-Augmented\n  Generation",
        "url": "http://arxiv.org/abs/2510.11358v1",
        "pub_date": "2025-10-13",
        "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge. While traditional retrieval focuses on relevance, RAG's effectiveness depends on the utility of retrieved passages, i.e., the usefulness in facilitating the generation of an accurate and comprehensive answer. Existing studies often treat utility as a generic attribute, ignoring the fact that different LLMs may benefit differently from the same passage due to variations in internal knowledge and comprehension ability. In this work, we introduce and systematically investigate the notion of LLM-specific utility. Through large-scale experiments across multiple datasets and LLMs, we demonstrate that human-annotated passages are not optimal for LLMs and that ground-truth utilitarian passages are not transferable across different LLMs. These findings highlight the necessity of adopting the LLM-specific utility in RAG research. Our findings indicate that some human-annotated passages are not ground-truth utilitarian passages for specific LLMs, partially due to the varying readability of queries and passages for LLMs, a tendency for which perplexity is a key metric. Based on these findings, we propose a benchmarking procedure for LLM-specific utility judgments. We evaluate existing utility judgment methods on six datasets and find that while verbalized methods using pseudo-answers perform robustly, LLMs struggle to assess utility effectively-failing to reject all passages for known queries and to select truly useful ones for unknown queries.",
        "translated": "检索增强生成（Retrieval-augmented Generation, RAG）通过引入外部知识来增强大语言模型（Large Language Models, LLMs）的能力。尽管传统检索方法主要关注相关性（relevance），但 RAG 的有效性依赖于检索到的段落的**效用性**（utility），即这些段落在促进生成准确且全面答案方面的有用程度。现有研究通常将效用性视为一种通用属性，忽视了由于不同 LLM 在内部知识和理解能力上的差异，它们可能从相同的段落中获得不同的收益。在本工作中，我们引入并系统地探讨了**面向特定 LLM 的效用性**（LLM-specific utility）这一概念。通过在多个数据集和 LLM 上的大规模实验，我们证明：人工标注的段落对 LLM 来说并非最优选择，并且真实效用性段落在不同 LLM 之间不可迁移。这些发现凸显了在 RAG 研究中采用 LLM-specific utility 的必要性。我们的研究表明，某些人工标注的段落对特定 LLM 而言并不是真实效用性段落，部分原因是 LLM 对查询和段落的可读性存在差异，而这种差异可以通过困惑度（perplexity）这一关键指标来衡量。基于上述发现，我们提出了一种面向 LLM-specific utility 的基准评估方法。我们对六种数据集上的现有效用性判断方法进行了评估，发现尽管使用伪答案（pseudo-answers）的显式化方法表现较为稳健，但 LLM 在评估段落效用性方面仍存在困难，无法拒绝所有已知查询的段落，也无法为未知查询有效挑选真正有用的段落。"
    },
    {
        "title": "Dynamic Network-Based Two-Stage Time Series Forecasting for Affiliate\n  Marketing",
        "url": "http://arxiv.org/abs/2510.11323v1",
        "pub_date": "2025-10-13",
        "summary": "In recent years, affiliate marketing has emerged as a revenue-sharing strategy where merchants collaborate with promoters to promote their products. It not only increases product exposure but also allows promoters to earn a commission. This paper addresses the pivotal yet under-explored challenge in affiliate marketing: accurately assessing and predicting the contributions of promoters in product promotion. We design a novel metric for evaluating the indirect contributions of the promoter, called propagation scale. Unfortunately, existing time series forecasting techniques fail to deliver accurate predictions due to the propagation scale being influenced by multiple factors and the inherent complexities arising from dynamic scenarios. To address this issue, we decouple the network structure from the node signals and propose a two-stage solution: initially, the basic self-sales and network structure prediction are conducted separately, followed by the synthesis of the propagation scale. Specifically, we design a graph convolution encoding scheme based on descendant neighbors and incorporate hypergraph convolution to efficiently capture complex promotional dynamics. Additionally, three auxiliary tasks are employed: self-sales prediction for base estimations, descendant prediction to synthesize propagation scale, and promoter activation prediction to mitigate high volatility issues. Extensive offline experiments on large-scale industrial datasets validate the superiority of our method. We further deploy our model on Alimama platform with over $100,000$ promoters, achieving a $9.29\\%$ improvement in GMV and a $5.89\\%$ increase in sales volume.",
        "translated": "近年来，联盟营销已成为一种收益共享策略，商家与推广者合作以推广其商品。这种模式不仅提高了商品的曝光度，还使推广者能够获得佣金。本文关注联盟营销中一个关键但尚未充分研究的问题：**准确评估和预测推广者在商品推广中的贡献**。我们设计了一种用于衡量推广者间接贡献的新指标，称为**传播规模（propagation scale）**。然而，由于传播规模受到多种因素影响，且动态场景中存在内在复杂性，现有的时间序列预测技术难以实现准确的预测。为了解决这一问题，我们**将网络结构与节点信号解耦**，并提出了一种两阶段的解决方案：首先，分别预测基本的自主销售与网络结构；随后，合成传播规模。具体而言，我们设计了一种基于后代邻居的图卷积编码方案，并引入超图卷积以高效捕捉复杂的推广动态。此外，我们还引入了三个辅助任务：用于基础估计的自主销售预测、用于合成传播规模的后代节点预测，以及用于缓解高波动性问题的推广者激活预测。我们在大规模工业数据集上进行了广泛的离线实验，验证了我们方法的优越性。我们进一步将模型部署在拥有超过100,000名推广者的Alimama平台，实现了GMV提升9.29%，销售量增长5.89%。"
    },
    {
        "title": "Next Interest Flow: A Generative Pre-training Paradigm for Recommender\n  Systems by Modeling All-domain Movelines",
        "url": "http://arxiv.org/abs/2510.11317v1",
        "pub_date": "2025-10-13",
        "summary": "Click-Through Rate (CTR) prediction, a cornerstone of modern recommender systems, has been dominated by discriminative models that react to past user behavior rather than proactively modeling user intent. Existing generative paradigms attempt to address this but suffer from critical limitations: Large Language Model (LLM) based methods create a semantic mismatch by forcing e-commerce signals into a linguistic space, while ID-based generation is constrained by item memorization and cold-start issues. To overcome these limitations, we propose a novel generative pre-training paradigm. Our model learns to predict the Next Interest Flow, a dense vector sequence representing a user's future intent, while simultaneously modeling its internal Interest Diversity and Interest Evolution Velocity to ensure the representation is both rich and coherent. However, this two-stage approach introduces a critical objective mismatch between the generative and discriminative stages. We resolve this via a bidirectional alignment strategy, which harmonizes the two stages through cross-stage weight initialization and a dynamic Semantic Alignment Module for fine-tuning. Additionally, we enhance the underlying discriminative model with a Temporal Sequential Pairwise (TSP) mechanism to better capture temporal causality. We present the All-domain Moveline Evolution Network (AMEN), a unified framework implementing our entire pipeline. Extensive offline experiments validate AMEN's superiority over strong baselines, and a large-scale online A/B test demonstrates its significant real-world impact, delivering substantial improvements in key business metrics.",
        "translated": "点击率（CTR）预测是现代推荐系统中的核心任务之一，目前主要依赖于判别式模型，这些模型侧重于响应用户过去的行为，而未能主动建模用户的意图。现有的生成式范式尝试解决这一问题，但存在关键的局限性：基于大语言模型（LLM）的方法将电商信号强行映射到语言语义空间，导致语义错配；而基于ID的生成方法则受到物品记忆能力和冷启动问题的限制。为克服这些限制，我们提出了一种新颖的生成式预训练范式。我们的模型旨在预测“下一个兴趣流”（Next Interest Flow），即一个稠密向量序列，用于表示用户未来的兴趣意图。同时，该模型还建模内部的兴趣多样性（Interest Diversity）和兴趣演化速度（Interest Evolution Velocity），以确保表示的丰富性与一致性。然而，这种两阶段的方法在生成阶段与判别阶段之间引入了关键的目标不匹配问题。我们通过双向对齐策略加以解决，该策略通过跨阶段权重初始化和动态语义对齐模块（Semantic Alignment Module）进行微调，从而协调两个阶段之间的差异。此外，我们通过引入时间序列成对机制（Temporal Sequential Pairwise, TSP）来增强底层判别模型，以更好地捕捉时间因果关系。我们提出了一个统一的框架——全领域兴趣演化网络（All-domain Moveline Evolution Network, AMEN），实现了我们完整的流水线。大量离线实验验证了AMEN在强基线模型上的优越性能，而大规模在线A/B测试也展示了其在现实场景中的显著影响，显著提升了关键业务指标。"
    },
    {
        "title": "ELMO: Efficiency via Low-precision and Peak Memory Optimization in Large\n  Output Spaces",
        "url": "http://arxiv.org/abs/2510.11168v1",
        "pub_date": "2025-10-13",
        "summary": "Large output spaces, also referred to as Extreme multilabel classification (XMC), is a setting that arises, e.g., in large-scale tagging and product-to-product recommendation, and is characterized by the number of labels ranging from hundreds of thousands to millions. This means that the linear classification head, usually only a tiny fraction of the overall model, turns into the main driver for compute and memory demand. Current state-of-the-art XMC methods predominantly rely on FP16-FP32 mixed-precision training, which we show can be unstable, and inefficient in terms of memory usage and computational overhead. Meanwhile, existing low-precision methods typically retain higher precision for the classification layer. In this work, we propose ELMO, a pure low-precision training framework for XMC models using BFloat16 and Float8 data types. By leveraging Kahan summation and stochastic rounding, we demonstrate that XMC models can be effectively trained entirely in Float8, without relying on single-precision master weights or tensor scaling. Low-precision training, combined with our proposed memory optimizations -- gradient fusion and chunking -- enables significant reductions in GPU memory usage. For example, we train a 3-million-label XMC model with only 6.6 GiB of GPU memory, compared to the 39.7 GiB required by the optimized SOTA method, Renee without compromising accuracy.",
        "translated": "大规模输出空间，也称为极端多标签分类（Extreme multilabel classification, XMC），是一种在大规模标签分配和商品到商品推荐等场景中常见的设定，其特点是标签数量可高达数十万到数百万级。这意味着线性分类头（通常在整个模型中仅占极小部分）变成了计算和内存需求的主要驱动因素。当前最先进的XMC方法主要依赖FP16与FP32混合精度训练，但我们发现这种方法在训练稳定性、内存使用效率以及计算开销方面存在不足。同时，现有的低精度训练方法通常仍为分类层保留较高精度。在本文中，我们提出ELMO，一个完全基于BFloat16和Float8数据类型的低精度训练框架。通过引入Kahan求和和随机舍入技术，我们证明XMC模型可以完全在Float8精度下进行有效训练，而无需依赖单精度主权重或张量缩放。结合我们提出的内存优化方法——梯度融合和块处理（chunking），该框架能够显著减少GPU内存的使用。例如，我们在仅使用6.6 GiB GPU内存的情况下训练了一个包含300万个标签的XMC模型，而优化后的SOTA方法Renee则需要39.7 GiB的内存，且在不损失精度的前提下实现了这一目标。"
    },
    {
        "title": "DyKnow-RAG: Dynamic Knowledge Utilization Reinforcement Framework for\n  Noisy Retrieval-Augmented Generation in E-commerce Search Relevance",
        "url": "http://arxiv.org/abs/2510.11122v1",
        "pub_date": "2025-10-13",
        "summary": "Accurately modeling query-item relevance drives e-commerce ranking, yet long-tail, knowledge-heavy, and fast-evolving queries exceed parametric LLM coverage. External context (reviews, attribute encyclopedias, UGC) can help but is noisy, and single-pass latency and cost forbid any clean-then-summarize step. The model must, per query, judge relevance and decide whether to use, partially use, or ignore the context. DyKnow-RAG is a dynamic noisy-RAG framework built on Group Relative Policy Optimization. It trains two rollout groups (no external context vs a single retrieved chunk) and applies posterior-driven inter-group advantage scaling that adaptively reweights their contributions by the per-query correctness gap. This teaches when to trust retrieval versus fall back to parametric knowledge, without process labels, value networks, or extra inference passes, preserving single-pass, single-chunk deployment under production latency. Training combines: (1) supervised initialization with a structured rationale that explicitly records the context-usage decision; (2) an RL pool prioritized by SFT uncertainty to focus where context choice is most consequential; and (3) an optional lightweight DPO warm start to stabilize with-context calibration. Under a unified retrieval/index and fixed latency budget, DyKnow-RAG outperforms SFT, DPO, and vanilla GRPO in offline tests, and delivers consistent lifts on GSB, Query Goodrate, and Item Goodrate in Taobao A/B testing. It is deployed in Taobao's production relevance system, serving live traffic. To our knowledge, it is among the first single-pass RAG solutions for e-commerce relevance, turning noisy external signals into reliable gains without added online complexity.",
        "translated": "准确地建模查询与商品的相关性对于电商排序至关重要，然而长尾、知识密集型和快速变化的查询超出了参数化大语言模型的覆盖范围。外部上下文（如商品评论、属性百科、用户生成内容）虽然可以提供帮助，但往往包含噪声，且单次推理的延迟和成本限制了任何“清理再摘要”的步骤。因此，模型必须在每次查询中判断相关性，并决定是否使用、部分使用或忽略外部上下文。\n\nDyKnow-RAG 是一种基于组相对策略优化（Group Relative Policy Optimization）的动态噪声-RAG框架。该框架通过训练两个 rollout 组（一组不使用外部上下文，另一组使用一个检索到的 chunk）并采用后验驱动的组间优势缩放方法，以查询间的准确性差距自适应地重新加权两组的贡献。这种方法能够在无需过程标签、价值网络或额外推理步骤的前提下，学习何时信任检索结果，何时回退至参数化知识，从而在生产延迟下保持单次推理、单 chunk 的部署效率。\n\nDyKnow-RAG 的训练结合了以下三个阶段：（1）结构化理由监督初始化，显式记录上下文使用决策；（2）以监督微调（SFT）的不确定性为优先级的强化学习（RL）池，集中于上下文选择最具影响的场景；（3）一个可选的轻量级 DPO 预训练阶段，用于稳定上下文相关校准。\n\n在统一的检索/索引设置和固定的延迟预算下，DyKnow-RAG 在离线测试中优于 SFT、DPO 和标准 GRPO。在淘宝的 A/B 测试中，该方法在 GSB、Query Goodrate 和 Item Goodrate 等指标上均实现了持续的提升。目前，DyKnow-RAG 已部署于淘宝的生产相关性系统中，服务实时流量。据我们所知，这是首批针对电商相关性问题的单次推理 RAG 解决方案之一，能够在不增加在线复杂度的前提下，将噪声外部信号转化为可靠收益。"
    },
    {
        "title": "Zero-Shot CFC: Fast Real-World Image Denoising based on Cross-Frequency\n  Consistency",
        "url": "http://arxiv.org/abs/2510.12646v1",
        "pub_date": "2025-10-14",
        "summary": "Zero-shot denoisers address the dataset dependency of deep-learning-based denoisers, enabling the denoising of unseen single images. Nonetheless, existing zero-shot methods suffer from long training times and rely on the assumption of noise independence and a zero-mean property, limiting their effectiveness in real-world denoising scenarios where noise characteristics are more complicated. This paper proposes an efficient and effective method for real-world denoising, the Zero-Shot denoiser based on Cross-Frequency Consistency (ZSCFC), which enables training and denoising with a single noisy image and does not rely on assumptions about noise distribution. Specifically, image textures exhibit position similarity and content consistency across different frequency bands, while noise does not. Based on this property, we developed cross-frequency consistency loss and an ultralight network to realize image denoising. Experiments on various real-world image datasets demonstrate that our ZSCFC outperforms other state-of-the-art zero-shot methods in terms of computational efficiency and denoising performance.",
        "translated": "零样本去噪器解决了基于深度学习的去噪器对数据集的依赖问题，使其能够对未见过的单张图像进行去噪。然而，现有的零样本方法训练时间较长，并且依赖于噪声独立性和零均值的假设，这在现实世界中噪声特性更为复杂的情况下限制了其去噪效果。本文提出了一种高效且有效的现实场景去噪方法——基于跨频段一致性的零样本去噪器（Zero-Shot Denoiser based on Cross-Frequency Consistency, ZSCFC），该方法仅需单张含噪图像即可完成训练与去噪，且不依赖于对噪声分布的假设。具体而言，图像的纹理在不同频段中表现出位置相似性和内容一致性，而噪声则不具备这一特性。基于该特性，我们设计了跨频段一致性损失函数，并构建了一个超轻量级网络以实现图像去噪。在多个现实世界图像数据集上的实验表明，与其它最先进的零样本方法相比，ZSCFC在计算效率和去噪性能方面均表现出色。"
    },
    {
        "title": "Normalization-equivariant Diffusion Models: Learning Posterior Samplers\n  From Noisy And Partial Measurements",
        "url": "http://arxiv.org/abs/2510.11964v1",
        "pub_date": "2025-10-13",
        "summary": "Diffusion models (DMs) have rapidly emerged as a powerful framework for image generation and restoration. However, existing DMs are primarily trained in a supervised manner by using a large corpus of clean images. This reliance on clean data poses fundamental challenges in many real-world scenarios, where acquiring noise-free data is hard or infeasible, and only noisy and potentially incomplete measurements are available. While some methods can train DMs using noisy data, they are generally effective only when the amount of noise is very mild or when some additional noise-free data is available. In addition, existing methods for training DMs from incomplete measurements require access to multiple complementary acquisition processes, an assumption that poses a significant practical limitation. Here we introduce the first approach for learning DMs for image restoration using only noisy measurement data from a single operator. As a first key contribution, we show that DMs, and more broadly minimum mean squared error denoisers, exhibit a weak form of scale equivariance linking rescaling in signal amplitude to changes in noise intensity. We then leverage this theoretical insight to develop a denoising score-matching strategy that generalizes robustly to noise levels lower than those present in the training data, thereby enabling the learning of DMs from noisy measurements. To further address the challenges of incomplete and noisy data, we integrate our method with equivariant imaging, a complementary self-supervised learning framework that exploits the inherent invariants of imaging problems, to train DMs for image restoration from single-operator measurements that are both incomplete and noisy. We validate the effectiveness of our approach through extensive experiments on image denoising, demosaicing, and inpainting, along with comparisons with the state of the art.",
        "translated": "扩散模型（DMs）已迅速成为图像生成与修复的强大框架。然而，现有的扩散模型主要依赖于大量干净图像的监督训练。这种对干净数据的依赖在许多现实场景中带来了根本性挑战，因为在这些场景中获取无噪声数据困难或不可行，仅有噪声干扰且可能不完整的测量数据可用。尽管已有方法尝试使用噪声数据训练扩散模型，但它们通常仅在噪声非常轻微或存在部分无噪声数据时才有效。此外，目前基于不完整测量数据训练扩散模型的方法通常需要多个互补的采集过程，这一假设在实践中构成了显著的限制。本文首次提出了一种仅使用单一操作算子的噪声测量数据来学习图像修复扩散模型的方法。作为我们的第一个关键贡献，我们证明了扩散模型，以及更广泛的最小均方误差去噪器，表现出一种弱形式的尺度等变性（scale equivariance），将信号幅值的缩放与噪声强度的变化联系起来。我们随后利用这一理论洞见，提出一种去噪得分匹配策略，该策略能够稳健地推广到训练数据中噪声水平更低的情况，从而实现基于噪声测量数据的扩散模型训练。为了进一步应对数据不完整和噪声的挑战，我们将该方法与等变成像（equivariant imaging）相结合，这是一种互补的自监督学习框架，利用了成像问题中的固有不变性，从而实现基于单一操作算子所获取的不完整且噪声干扰数据的图像修复扩散模型训练。我们在图像去噪、色彩插值（demosaicing）和修复（inpainting）任务上进行了广泛的实验验证，并与当前最先进的方法进行了对比。"
    },
    {
        "title": "Enabling High-Quality In-the-Wild Imaging from Severely Aberrated\n  Metalens Bursts",
        "url": "http://arxiv.org/abs/2510.10083v1",
        "pub_date": "2025-10-11",
        "summary": "We tackle the challenge of robust, in-the-wild imaging using ultra-thin nanophotonic metalens cameras. Meta-lenses, composed of planar arrays of nanoscale scatterers, promise dramatic reductions in size and weight compared to conventional refractive optics. However, severe chromatic aberration, pronounced light scattering, narrow spectral bandwidth, and low light efficiency continue to limit their practical adoption. In this work, we present an end-to-end solution for in-the-wild imaging that pairs a metalens several times thinner than conventional optics with a bespoke multi-image restoration framework optimized for practical metalens cameras. Our method centers on a lightweight convolutional network paired with a memory-efficient burst fusion algorithm that adaptively corrects noise, saturation clipping, and lens-induced distortions across rapid sequences of extremely degraded metalens captures. Extensive experiments on diverse, real-world handheld captures demonstrate that our approach consistently outperforms existing burst-mode and single-image restoration techniques.These results point toward a practical route for deploying metalens-based cameras in everyday imaging applications.",
        "translated": "我们针对使用超薄纳米光学金属透镜相机在真实环境下的鲁棒成像问题提出了一个解决方案。金属透镜由平面排列的纳米级散射体构成，相较于传统的折射式光学元件，有望显著减小尺寸和重量。然而，严重的色差、明显的光散射、狭窄的光谱带宽以及低光效率等问题仍限制了其实际应用。在本工作中，我们提出了一种端到端的真实环境下成像方案，该方案结合了一种比传统光学元件薄几倍的金属透镜，以及一种为实际金属透镜相机量身定制、高效的多图像复原框架。我们的方法核心是一个轻量级卷积网络，结合了一种内存高效的图像序列融合算法，能够自适应地校正在快速拍摄的严重退化金属透镜图像序列中出现的噪声、饱和裁剪和透镜引起的失真。我们在多种实际手持拍摄数据上进行了广泛的实验，结果表明，我们的方法在性能上持续优于现有的突发模式和单图像复原技术。这些结果表明，基于金属透镜的相机在日常成像应用中具有实际可行的部署路径。"
    },
    {
        "title": "Denoising Diffusion as a New Framework for Underwater Images",
        "url": "http://arxiv.org/abs/2510.09934v1",
        "pub_date": "2025-10-11",
        "summary": "Underwater images play a crucial role in ocean research and marine environmental monitoring since they provide quality information about the ecosystem. However, the complex and remote nature of the environment results in poor image quality with issues such as low visibility, blurry textures, color distortion, and noise. In recent years, research in image enhancement has proven to be effective but also presents its own limitations, like poor generalization and heavy reliance on clean datasets. One of the challenges herein is the lack of diversity and the low quality of images included in these datasets. Also, most existing datasets consist only of monocular images, a fact that limits the representation of different lighting conditions and angles. In this paper, we propose a new plan of action to overcome these limitations. On one hand, we call for expanding the datasets using a denoising diffusion model to include a variety of image types such as stereo, wide-angled, macro, and close-up images. On the other hand, we recommend enhancing the images using Controlnet to evaluate and increase the quality of the corresponding datasets, and hence improve the study of the marine ecosystem.   Tags - Underwater Images, Denoising Diffusion, Marine ecosystem, Controlnet",
        "translated": "水下图像在海洋研究和海洋环境监测中起着至关重要的作用，因为它们提供了有关生态系统的重要信息。然而，由于环境的复杂性和远离人类的特性，所获取的图像质量通常较差，存在诸如能见度低、纹理模糊、颜色失真和噪声等问题。近年来，图像增强的研究已被证明是有效的，但也存在自身局限性，例如泛化能力差和对干净数据集的依赖性较强。其中一大挑战是这些数据集中图像的多样性不足且质量偏低。此外，大多数现有数据集仅包含单目图像，这一事实限制了不同光照条件和角度的表征能力。本文中，我们提出了一种新的应对方案以克服这些局限性。一方面，我们建议使用去噪扩散模型（denoising diffusion model）扩展数据集，包含诸如双目、广角、微距和特写等多种图像类型；另一方面，我们推荐使用 ControlNet 对图像进行增强，以评估并提升相应数据集的质量，从而促进对海洋生态系统的研究。  \n标签 - 水下图像，去噪扩散，海洋生态系统，ControlNet"
    },
    {
        "title": "Defense against Unauthorized Distillation in Image Restoration via\n  Feature Space Perturbation",
        "url": "http://arxiv.org/abs/2510.08925v1",
        "pub_date": "2025-10-10",
        "summary": "Knowledge distillation (KD) attacks pose a significant threat to deep model intellectual property by enabling adversaries to train student networks using a teacher model's outputs. While recent defenses in image classification have successfully disrupted KD by perturbing output probabilities, extending these methods to image restoration is difficult. Unlike classification, restoration is a generative task with continuous, high-dimensional outputs that depend on spatial coherence and fine details. Minor perturbations are often insufficient, as students can still learn the underlying mapping.To address this, we propose Adaptive Singular Value Perturbation (ASVP), a runtime defense tailored for image restoration models. ASVP operates on internal feature maps of the teacher using singular value decomposition (SVD). It amplifies the topk singular values to inject structured, high-frequency perturbations, disrupting the alignment needed for distillation. This hinders student learning while preserving the teacher's output quality.We evaluate ASVP across five image restoration tasks: super-resolution, low-light enhancement, underwater enhancement, dehazing, and deraining. Experiments show ASVP reduces student PSNR by up to 4 dB and SSIM by 60-75%, with negligible impact on the teacher's performance. Compared to prior methods, ASVP offers a stronger and more consistent defense.Our approach provides a practical solution to protect open-source restoration models from unauthorized knowledge distillation.",
        "translated": "知识蒸馏（Knowledge Distillation, KD）攻击通过使对手能够利用教师模型的输出来训练学生网络，对深度模型的知识产权构成了重大威胁。尽管图像分类领域的最新防御方法已成功通过扰动输出概率来破坏知识蒸馏，但将这些方法扩展到图像恢复任务却面临困难。与分类任务不同，图像恢复是一个生成任务，其输出是连续且高维的，依赖于空间一致性和细节质量。因此，微小的扰动往往不足以阻止知识蒸馏，因为学生模型仍能学习到潜在的映射关系。\n\n为了解决这一问题，我们提出了一种专为图像恢复模型设计的运行时防御方法——自适应奇异值扰动（Adaptive Singular Value Perturbation, ASVP）。ASVP 通过奇异值分解（Singular Value Decomposition, SVD）对教师模型的内部特征图进行操作。该方法通过放大前k个奇异值，注入结构化的高频扰动，从而破坏蒸馏过程中所需的对齐关系。这种扰动在阻碍学生模型学习的同时，保持了教师模型的输出质量。\n\n我们在五个图像恢复任务中评估了 ASVP：超分辨率、低光增强、水下增强、去雾和去雨。实验结果表明，ASVP 最多可使学生模型的 PSNR 降低 4 dB，SSIM 降低 60-75%，而对教师模型的性能影响几乎可以忽略。与现有方法相比，ASVP 提供了更强且更一致的防御效果。我们的方法为保护开源图像恢复模型免受未经授权的知识蒸馏提供了一个实用的解决方案。"
    },
    {
        "title": "Latent Harmony: Synergistic Unified UHD Image Restoration via Latent\n  Space Regularization and Controllable Refinement",
        "url": "http://arxiv.org/abs/2510.07961v2",
        "pub_date": "2025-10-09",
        "summary": "Ultra-High Definition (UHD) image restoration faces a trade-off between computational efficiency and high-frequency detail retention. While Variational Autoencoders (VAEs) improve efficiency via latent-space processing, their Gaussian constraint often discards degradation-specific high-frequency information, hurting reconstruction fidelity. To overcome this, we propose Latent Harmony, a two-stage framework that redefines VAEs for UHD restoration by jointly regularizing the latent space and enforcing high-frequency-aware reconstruction.In Stage One, we introduce LH-VAE, which enhances semantic robustness through visual semantic constraints and progressive degradation perturbations, while latent equivariance strengthens high-frequency reconstruction.Stage Two jointly trains this refined VAE with a restoration model using High-Frequency Low-Rank Adaptation (HF-LoRA): an encoder LoRA guided by a fidelity-oriented high-frequency alignment loss to recover authentic details, and a decoder LoRA driven by a perception-oriented loss to synthesize realistic textures. Both LoRA modules are trained via alternating optimization with selective gradient propagation to preserve the pretrained latent structure.At inference, a tunable parameter {\\alpha} enables flexible fidelity-perception trade-offs.Experiments show Latent Harmony achieves state-of-the-art performance across UHD and standard-resolution tasks, effectively balancing efficiency, perceptual quality, and reconstruction accuracy.",
        "translated": "超高分辨率（UHD）图像修复面临计算效率与高频细节保留之间的权衡。尽管变分自编码器（VAEs）通过潜在空间处理提升了效率，但其高斯约束常常会丢弃与退化相关的高频信息，从而损害重建的保真度。为了解决这一问题，我们提出了**Latent Harmony**，一种两阶段框架，通过联合正则化潜在空间并强制实现高频感知的重建，重新定义了用于UHD图像修复的VAEs。  \n\n在第一阶段中，我们引入了**LH-VAE**，该模型通过视觉语义约束和渐进式退化扰动来增强语义鲁棒性，同时利用潜在等变性来强化高频信息的重建。  \n\n在第二阶段中，我们将优化后的VAE与一个修复模型联合训练，采用**高频低秩适配（High-Frequency Low-Rank Adaptation, HF-LoRA）**方法：一个编码器LoRA通过以保真度为导向的高频对齐损失（high-frequency alignment loss）来恢复真实细节，而一个解码器LoRA则由以感知为导向的损失驱动，以合成逼真的纹理。两个LoRA模块通过交替优化与选择性梯度传播进行训练，从而保持预训练的潜在结构不变。  \n\n在推理阶段，一个可调节的参数 $\\alpha$ 可实现保真度与感知质量之间的灵活权衡。实验表明，**Latent Harmony**在UHD和标准分辨率任务中均达到了最先进的性能，有效平衡了计算效率、感知质量与重建精度。"
    },
    {
        "title": "PhyDAE: Physics-Guided Degradation-Adaptive Experts for All-in-One\n  Remote Sensing Image Restoration",
        "url": "http://arxiv.org/abs/2510.08653v1",
        "pub_date": "2025-10-09",
        "summary": "Remote sensing images inevitably suffer from various degradation factors during acquisition, including atmospheric interference, sensor limitations, and imaging conditions. These complex and heterogeneous degradations pose severe challenges to image quality and downstream interpretation tasks. Addressing limitations of existing all-in-one restoration methods that overly rely on implicit feature representations and lack explicit modeling of degradation physics, this paper proposes Physics-Guided Degradation-Adaptive Experts (PhyDAE). The method employs a two-stage cascaded architecture transforming degradation information from implicit features into explicit decision signals, enabling precise identification and differentiated processing of multiple heterogeneous degradations including haze, noise, blur, and low-light conditions. The model incorporates progressive degradation mining and exploitation mechanisms, where the Residual Manifold Projector (RMP) and Frequency-Aware Degradation Decomposer (FADD) comprehensively analyze degradation characteristics from manifold geometry and frequency perspectives. Physics-aware expert modules and temperature-controlled sparse activation strategies are introduced to enhance computational efficiency while ensuring imaging physics consistency. Extensive experiments on three benchmark datasets (MD-RSID, MD-RRSHID, and MDRS-Landsat) demonstrate that PhyDAE achieves superior performance across all four restoration tasks, comprehensively outperforming state-of-the-art methods. Notably, PhyDAE substantially improves restoration quality while achieving significant reductions in parameter count and computational complexity, resulting in remarkable efficiency gains compared to mainstream approaches and achieving optimal balance between performance and efficiency. Code is available at https://github.com/HIT-SIRS/PhyDAE.",
        "translated": "遥感图像在获取过程中不可避免地受到多种退化因素的影响，包括大气干扰、传感器限制以及成像条件等。这些复杂且异质的退化现象给图像质量以及后续的语义解析任务带来了严重挑战。为了解决现有端到端图像修复方法中对隐式特征表示的过度依赖以及缺乏对退化物理机制的显式建模等问题，本文提出了一种物理引导的退化自适应专家模型（Physics-Guided Degradation-Adaptive Experts, PhyDAE）。该方法采用两阶段级联架构，将隐式特征中的退化信息转化为显式的决策信号，从而实现对多种异质退化（包括雾霾、噪声、模糊和低光照条件）的精确识别与差异化处理。模型引入了渐进式退化挖掘与利用机制，其中残差流形投影器（Residual Manifold Projector, RMP）和频域感知退化解耦模块（Frequency-Aware Degradation Decomposer, FADD）分别从流形几何结构和频域角度对退化特性进行全面分析。此外，通过引入物理感知的专家模块和温度控制的稀疏激活策略，在保证成像物理一致性的同时显著提升了计算效率。在三个基准数据集（MD-RSID、MD-RRSHID 和 MDRS-Landsat）上的大量实验表明，PhyDAE 在四项图像修复任务中均表现出优越的性能，全面超越现有最先进方法。特别值得一提的是，PhyDAE 在大幅提升修复质量的同时，显著减少了模型参数数量与计算复杂度，从而在主流方法中实现了性能与效率之间的最优平衡。代码可在 https://github.com/HIT-SIRS/PhyDAE 获取。"
    },
    {
        "title": "DeRainMamba: A Frequency-Aware State Space Model with Detail Enhancement\n  for Image Deraining",
        "url": "http://arxiv.org/abs/2510.06746v1",
        "pub_date": "2025-10-08",
        "summary": "Image deraining is crucial for improving visual quality and supporting reliable downstream vision tasks. Although Mamba-based models provide efficient sequence modeling, their limited ability to capture fine-grained details and lack of frequency-domain awareness restrict further improvements. To address these issues, we propose DeRainMamba, which integrates a Frequency-Aware State-Space Module (FASSM) and Multi-Directional Perception Convolution (MDPConv). FASSM leverages Fourier transform to distinguish rain streaks from high-frequency image details, balancing rain removal and detail preservation. MDPConv further restores local structures by capturing anisotropic gradient features and efficiently fusing multiple convolution branches. Extensive experiments on four public benchmarks demonstrate that DeRainMamba consistently outperforms state-of-the-art methods in PSNR and SSIM, while requiring fewer parameters and lower computational costs. These results validate the effectiveness of combining frequency-domain modeling and spatial detail enhancement within a state-space framework for single image deraining.",
        "translated": "图像去雨对于提升视觉质量和支持可靠的下游视觉任务至关重要。尽管基于Mamba的模型在序列建模方面具有较高的效率，但其在捕捉细粒度细节方面的能力有限以及缺乏频域感知，限制了进一步的性能提升。为解决这些问题，我们提出DeRainMamba，该方法融合了一个频域感知状态空间模块（Frequency-Aware State-Space Module, FASSM）和多方向感知卷积（Multi-Directional Perception Convolution, MDPConv）。FASSM利用傅里叶变换区分雨痕与图像中的高频细节，从而在去雨与细节保留之间取得平衡。MDPConv通过捕捉各向异性梯度特征并高效融合多分支卷积，进一步恢复局部结构。我们在四个公开基准数据集上进行了广泛的实验，结果表明DeRainMamba在PSNR和SSIM指标上始终优于当前最先进的方法，同时参数量更少，计算成本更低。这些结果验证了在状态空间框架中结合频域建模与空间细节增强对于单图像去雨的有效性。"
    },
    {
        "title": "An Inertial Langevin Algorithm",
        "url": "http://arxiv.org/abs/2510.06723v1",
        "pub_date": "2025-10-08",
        "summary": "We present a novel method for drawing samples from Gibbs distributions with densities of the form $\\pi(x) \\propto \\exp(-U(x))$. The method accelerates the unadjusted Langevin algorithm by introducing an inertia term similar to Polyak's heavy ball method, together with a corresponding noise rescaling. Interpreting the scheme as a discretization of \\emph{kinetic} Langevin dynamics, we prove ergodicity (in continuous and discrete time) for twice continuously differentiable, strongly convex, and $L$-smooth potentials and bound the bias of the discretization to the target in Wasserstein-2 distance. In particular, the presented proofs allow for smaller friction parameters in the kinetic Langevin diffusion compared to existing literature. Moreover, we show the close ties of the proposed method to the over-relaxed Gibbs sampler. The scheme is tested in an extensive set of numerical experiments covering simple toy examples, total variation image denoising, and the complex task of maximum likelihood learning of an energy-based model for molecular structure generation. The experimental results confirm the acceleration provided by the proposed scheme even beyond the strongly convex and $L$-smooth setting.",
        "translated": "我们提出了一种从形式为 $\\pi(x) \\propto \\exp(-U(x))$ 的 Gibbs 分布中抽样的新方法。该方法通过引入类似于 Polyak 重球法的惯性项以及相应的噪声重缩放机制，加速了未调整的 Langevin 算法。将该方法解释为对 \\emph{动能} Langevin 动力学的离散化，我们证明了在连续和离散时间下，对于二次连续可微、强凸且 $L$-光滑的势函数，该方法具有遍历性，并在 Wasserstein-2 距离下对该离散化方案与目标分布之间的偏差进行了上界分析。特别地，所提出的证明允许在动能 Langevin 扩散中使用比现有文献中更小的摩擦参数。此外，我们展示了该方法与过松弛 Gibbs 抽样器之间的紧密联系。该算法在一个广泛的数值实验中进行了测试，涵盖简单的玩具示例、图像的全变分去噪任务，以及分子结构生成的能量基模型的最大似然学习这一复杂任务。实验结果验证了所提出方法即使在非强凸和非 $L$-光滑的设置下仍能提供加速效果。"
    },
    {
        "title": "AIM 2025 Challenge on Real-World RAW Image Denoising",
        "url": "http://arxiv.org/abs/2510.06601v1",
        "pub_date": "2025-10-08",
        "summary": "We introduce the AIM 2025 Real-World RAW Image Denoising Challenge, aiming to advance efficient and effective denoising techniques grounded in data synthesis. The competition is built upon a newly established evaluation benchmark featuring challenging low-light noisy images captured in the wild using five different DSLR cameras. Participants are tasked with developing novel noise synthesis pipelines, network architectures, and training methodologies to achieve high performance across different camera models. Winners are determined based on a combination of performance metrics, including full-reference measures (PSNR, SSIM, LPIPS), and non-reference ones (ARNIQA, TOPIQ). By pushing the boundaries of camera-agnostic low-light RAW image denoising trained on synthetic data, the competition promotes the development of robust and practical models aligned with the rapid progress in digital photography. We expect the competition outcomes to influence multiple domains, from image restoration to night-time autonomous driving.",
        "translated": "我们介绍了AIM 2025真实世界RAW图像去噪挑战赛，旨在通过数据合成推动高效且有效的去噪技术的发展。该竞赛基于一个新的评估基准构建，该基准包含在自然场景下使用五种不同DSLR相机拍摄的具有挑战性的低光照噪声图像。参赛者需要开发新颖的噪声合成流程、网络架构和训练方法，以在不同相机模型上实现高性能的去噪效果。比赛的优胜者将根据多种性能指标综合评定，包括全参考指标（PSNR、SSIM、LPIPS）和非参考指标（ARNIQA、TOPIQ）。通过推动在合成数据上训练的、具有相机泛化能力的低光照RAW图像去噪技术的边界，该竞赛促进了与数字摄影快速进步相契合的鲁棒且实用模型的发展。我们预期本次竞赛的成果将对多个领域产生影响，从图像修复到夜间自动驾驶。"
    },
    {
        "title": "TDiff: Thermal Plug-And-Play Prior with Patch-Based Diffusion",
        "url": "http://arxiv.org/abs/2510.06460v1",
        "pub_date": "2025-10-07",
        "summary": "Thermal images from low-cost cameras often suffer from low resolution, fixed pattern noise, and other localized degradations. Available datasets for thermal imaging are also limited in both size and diversity. To address these challenges, we propose a patch-based diffusion framework (TDiff) that leverages the local nature of these distortions by training on small thermal patches. In this approach, full-resolution images are restored by denoising overlapping patches and blending them using smooth spatial windowing. To our knowledge, this is the first patch-based diffusion framework that models a learned prior for thermal image restoration across multiple tasks. Experiments on denoising, super-resolution, and deblurring demonstrate strong results on both simulated and real thermal data, establishing our method as a unified restoration pipeline.",
        "translated": "低成本热成像相机所获取的图像通常存在分辨率较低、固定模式噪声以及其他局部退化问题。目前可用的热成像数据集在规模和多样性方面也较为有限。为了解决这些挑战，我们提出了一种基于图像块的扩散框架（TDiff），该框架通过在小尺寸热图像块上进行训练，利用这些退化现象的局部特性。在该方法中，通过去噪重叠图像块，并结合平滑的空间窗口函数进行融合，从而恢复全分辨率图像。据我们所知，这是首个基于图像块的扩散框架，能够在多个任务中对热图像的退化建模并学习其先验分布。我们在去噪、超分辨率和去模糊任务上的实验表明，该方法在模拟和真实热图像数据上均取得了优异的效果，从而确立了其作为统一图像恢复流程的地位。"
    },
    {
        "title": "Local MAP Sampling for Diffusion Models",
        "url": "http://arxiv.org/abs/2510.07343v2",
        "pub_date": "2025-10-07",
        "summary": "Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to inverse problems by sampling from $p(x_0 \\mid y)$. However, in practice, the goal of inverse problem solving is not to cover the posterior but to recover the most accurate reconstruction, where optimization-based diffusion solvers often excel despite lacking a clear probabilistic foundation. We introduce Local MAP Sampling (LMAPS), a new inference framework that iteratively solving local MAP subproblems along the diffusion trajectory. This perspective clarifies their connection to global MAP estimation and DPS, offering a unified probabilistic interpretation for optimization-based methods. Building on this foundation, we develop practical algorithms with a probabilistically interpretable covariance approximation, a reformulated objective for stability and interpretability, and a gradient approximation for non-differentiable operators. Across a broad set of image restoration and scientific tasks, LMAPS achieves state-of-the-art performance, including $\\geq 2$ dB gains on motion deblurring, JPEG restoration, and quantization, and $&gt;1.5$ dB improvements on inverse scattering benchmarks.",
        "translated": "扩散后验采样（Diffusion Posterior Sampling, DPS）通过从 $p(x_0 \\mid y)$ 中采样，为逆问题提供了一种基于贝叶斯原理的求解方法。然而，实际上，解决逆问题的目标并非是覆盖后验分布，而是恢复最精确的重建结果，在这一点上，基于优化的扩散求解器往往表现出色，尽管它们缺乏明确的概率基础。我们提出一种新的推理框架——局部最大后验采样（Local MAP Sampling, LMAPS），该方法沿着扩散轨迹迭代求解局部最大后验（MAP）子问题。这一视角明确了LMAPS与全局MAP估计以及DPS之间的关系，为基于优化的方法提供了一种统一的概率解释。基于这一理论基础，我们开发了具有概率解释的协方差近似方法，提出了一个用于提高稳定性和可解释性的重构目标函数，并引入了针对不可微操作符的梯度近似方法。在广泛的图像恢复和科学计算任务中，LMAPS实现了最先进的性能，包括在运动去模糊、JPEG图像恢复和量化任务中获得了 $\\geq 2$ dB 的提升，在逆散射基准测试中实现了 $>1.5$ dB 的性能改进。"
    },
    {
        "title": "Rasterized Steered Mixture of Experts for Efficient 2D Image Regression",
        "url": "http://arxiv.org/abs/2510.05814v1",
        "pub_date": "2025-10-07",
        "summary": "The Steered Mixture of Experts regression framework has demonstrated strong performance in image reconstruction, compression, denoising, and super-resolution. However, its high computational cost limits practical applications. This work introduces a rasterization-based optimization strategy that combines the efficiency of rasterized Gaussian kernel rendering with the edge-aware gating mechanism of the Steered Mixture of Experts. The proposed method is designed to accelerate two-dimensional image regression while maintaining the model's inherent sparsity and reconstruction quality. By replacing global iterative optimization with a rasterized formulation, the method achieves significantly faster parameter updates and more memory-efficient model representations. In addition, the proposed framework supports applications such as native super-resolution and image denoising, which are not directly achievable with standard rasterized Gaussian kernel approaches. The combination of fast rasterized optimization with the edge-aware structure of the Steered Mixture of Experts provides a new balance between computational efficiency and reconstruction fidelity for two-dimensional image processing tasks.",
        "translated": "基于引导的专家混合（Steered Mixture of Experts）回归框架在图像重建、压缩、去噪和超分辨率等任务中已展现出优异的性能。然而，其较高的计算成本限制了其在实际应用中的使用。本文提出了一种基于光栅化的优化策略，结合了光栅化高斯核渲染的高效性与Steered Mixture of Experts中边缘感知门控机制的优势。所提出的方法旨在加速二维图像回归过程，同时保持模型固有的稀疏性与重建质量。通过将全局迭代优化替换为光栅化形式，该方法显著提高了参数更新速度，并实现了更节省内存的模型表示。此外，该框架支持诸如原生超分辨率和图像去噪等应用，而这些是标准光栅化高斯核方法无法直接实现的。快速光栅化优化与Steered Mixture of Experts边缘感知结构的结合，为二维图像处理任务提供了计算效率与重建保真度之间的新平衡。"
    },
    {
        "title": "Adaptive double-phase Rudin--Osher--Fatemi denoising model",
        "url": "http://arxiv.org/abs/2510.04382v1",
        "pub_date": "2025-10-05",
        "summary": "We propose a new image denoising model based on a variable-growth total variation regularization of double-phase type with adaptive weight. It is designed to reduce staircasing with respect to the classical Rudin--Osher--Fatemi model, while preserving the edges of the image in a similar fashion. We implement the model and test its performance on synthetic and natural images in 1D and 2D over a range of noise levels.",
        "translated": "我们提出了一种新的图像去噪模型，该模型基于具有自适应权重的双阶段可变增长总体变差正则化。该模型旨在相较于经典的 Rudin–Osher–Fatemi 模型，减少阶梯效应（staircasing），同时以类似的方式保留图像的边缘。我们对该模型进行了实现，并在 1D 和 2D 的合成图像与自然图像上，针对多种噪声水平进行了性能测试。"
    },
    {
        "title": "Equilibrium Matching: Generative Modeling with Implicit Energy-Based\n  Models",
        "url": "http://arxiv.org/abs/2510.02300v3",
        "pub_date": "2025-10-02",
        "summary": "We introduce Equilibrium Matching (EqM), a generative modeling framework built from an equilibrium dynamics perspective. EqM discards the non-equilibrium, time-conditional dynamics in traditional diffusion and flow-based generative models and instead learns the equilibrium gradient of an implicit energy landscape. Through this approach, we can adopt an optimization-based sampling process at inference time, where samples are obtained by gradient descent on the learned landscape with adjustable step sizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation performance of diffusion/flow models empirically, achieving an FID of 1.90 on ImageNet 256$\\times$256. EqM is also theoretically justified to learn and sample from the data manifold. Beyond generation, EqM is a flexible framework that naturally handles tasks including partially noised image denoising, OOD detection, and image composition. By replacing time-conditional velocities with a unified equilibrium landscape, EqM offers a tighter bridge between flow and energy-based models and a simple route to optimization-driven inference.",
        "translated": "我们提出了一种名为**均衡匹配**（Equilibrium Matching, EqM）的生成建模框架，其构建基于**均衡动力学**的视角。EqM摒弃了传统扩散模型和基于流的生成模型中所依赖的非均衡、时序条件的动力学，转而学习一个隐式能量景观的**均衡梯度**。通过这种方法，我们可以在推理阶段采用基于优化的采样过程，其中样本通过在所学能量景观上进行梯度下降获得，该过程支持可调节的步长、自适应优化器以及自适应计算能力。从实证结果来看，EqM在生成性能上超越了扩散模型和流模型，在ImageNet 256$\\times$256数据集上达到了1.90的FID分数。EqM在理论上也能够从数据流形中进行学习与采样，具有坚实的理论依据。除生成任务外，EqM还是一种灵活的框架，天然地适用于包括部分噪声图像去噪、分布外（OOD）检测以及图像合成在内的多种任务。通过将时序条件的速度替换为统一的均衡景观，EqM在流模型与基于能量的模型之间架起了更紧密的桥梁，并为实现优化驱动的推理提供了一条简洁的路径。"
    }
]